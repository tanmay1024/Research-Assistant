{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jY7mmcj9pRcW",
    "outputId": "9f036794-8ba3-4fa3-9c49-38b67e4bfada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# verify GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GXkks0-AsEz",
    "outputId": "fcea7de1-7391-477a-8e34-4f8f0b66798c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yxu0iAvYsHTK",
    "outputId": "c0ea1ce6-d9dc-4663-d892-f654ed7e5859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 5.8MB/s \n",
      "\u001b[?25hCollecting pytorch-nlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 10.6MB/s \n",
      "\u001b[?25hCollecting pytorch_transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 52.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c0/db041aa805b6275b52a02e15457fc4615f80226516b9bef3d59565538ec4/boto3-1.16.59-py2.py3-none-any.whl (130kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 55.4MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 43.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "Collecting botocore<1.20.0,>=1.19.59\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/10/08dc3b74cc9c47a2c81b2e88e06c2661783b86fd77fc80f7a3eb1bf56905/botocore-1.19.59-py2.py3-none-any.whl (7.2MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2MB 48.1MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.59->boto3->pytorch-pretrained-bert) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=f8383e4e9fe988cf532eb96c97e74e637e3411407b13adbd12155b304f1677ee\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "\u001b[31mERROR: botocore 1.19.59 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp, sacremoses, sentencepiece, pytorch-transformers\n",
      "Successfully installed boto3-1.16.59 botocore-1.19.59 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.2.0 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "# install huggingface libraries\n",
    "!pip install pytorch-pretrained-bert pytorch-nlp pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqd8Nwwnuh3u"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig, BertModel\n",
    "from pytorch_transformers import AdamW, BertForQuestionAnswering\n",
    "from pytorch_transformers import DistilBertTokenizer, DistilBertModel, DistilBertForQuestionAnswering\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "x9ANT1FssMH4",
    "outputId": "6042431e-abf8-45e4-c2cd-668489e07137"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT imports\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iU_9EqSXEFEj",
    "outputId": "393c09c2-6360-45b1-d464-e4794c1d0d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/data1\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My Drive/data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcCOg8XsEQ0P",
    "outputId": "fce8032e-6d8b-4311-a82a-8c18ba2af33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoint-145\u001b[0m/         predictions.json  utils_squad_evaluate.py\n",
      "\u001b[01;34mcheckpoint-150\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/      utils_squad.py\n",
      "nbest_predictions.json  results.json\n",
      "null_odds.json          train-v2.0.json\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yxjlwseeykl"
   },
   "outputs": [],
   "source": [
    "from utils_squad import (read_squad_examples, convert_examples_to_features,\n",
    "                         RawResult, write_predictions,\n",
    "                         RawResultExtended, write_predictions_extended)\n",
    "from utils_squad_evaluate import EVAL_OPTS, main as evaluate_on_squad, plot_pr_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGVWI85yfaPs",
    "outputId": "e3c1ba10-ca8f-4b5e-fadb-09cc29e86fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHgpndcloLFp"
   },
   "outputs": [],
   "source": [
    "input_file = 'train-v2.0.json'\n",
    "examples = read_squad_examples(input_file=input_file,\n",
    "                                is_training=True,\n",
    "                                version_2_with_negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVeg2Gw2mJYc",
    "outputId": "ac85e506-ed4c-4c00-b62c-1caf9e7036bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[qas_id: 56be85543aeaaa14008c9063, question_text: When did Beyonce start becoming popular?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 39, end_position: 42,\n",
       " qas_id: 56be85543aeaaa14008c9065, question_text: What areas did Beyonce compete in when she was growing up?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 28, end_position: 30,\n",
       " qas_id: 56be85543aeaaa14008c9066, question_text: When did Beyonce leave Destiny's Child and become a solo singer?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 82, end_position: 82,\n",
       " qas_id: 56bf6b0f3aeaaa14008c9601, question_text: In what city and state did Beyonce  grow up? , doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 22, end_position: 23,\n",
       " qas_id: 56bf6b0f3aeaaa14008c9602, question_text: In which decade did Beyonce become famous?, doc_tokens: [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".], start_position: 41, end_position: 42]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "TWRV-Q10qrIM",
    "outputId": "eaeeabce-e465-4e8e-d80d-0e84ac4b9abd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qas_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>doc_tokens</th>\n",
       "      <th>orig_answer_text</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
       "      <td>2003</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>[Beyoncé, Giselle, Knowles-Carter, (/biːˈjɒnse...</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     qas_id  ... is_impossible\n",
       "0  56be85543aeaaa14008c9063  ...         False\n",
       "1  56be85543aeaaa14008c9065  ...         False\n",
       "2  56be85543aeaaa14008c9066  ...         False\n",
       "3  56bf6b0f3aeaaa14008c9601  ...         False\n",
       "4  56bf6b0f3aeaaa14008c9602  ...         False\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame.from_records([vars(example) for example in examples])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "cNVta-8TrNN8",
    "outputId": "dcf2ad48-44d0-4427-a996-7a244764b05d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qas_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>doc_tokens</th>\n",
       "      <th>orig_answer_text</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>is_impossible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71428</th>\n",
       "      <td>572719a45951b619008f85f7</td>\n",
       "      <td>What is one type of configuration in which a c...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td>axially</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71429</th>\n",
       "      <td>572719a45951b619008f85f8</td>\n",
       "      <td>What is another type of configuration in which...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td>radially</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71430</th>\n",
       "      <td>572719a45951b619008f85f9</td>\n",
       "      <td>Which type of configuration is often manufactu...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td>Radial</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71431</th>\n",
       "      <td>572719a45951b619008f85fa</td>\n",
       "      <td>How are the leads of an axially configured cap...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td>on a common axis</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71432</th>\n",
       "      <td>572719a45951b619008f85fb</td>\n",
       "      <td>How could radial leads be more correctly descr...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td>as tandem</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71433</th>\n",
       "      <td>5acf762a77cf76001a684e64</td>\n",
       "      <td>What is one type of configuration in which a c...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71434</th>\n",
       "      <td>5acf762a77cf76001a684e65</td>\n",
       "      <td>What is another type of configuration in which...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71435</th>\n",
       "      <td>5acf762a77cf76001a684e66</td>\n",
       "      <td>Which type of configuration is never manufactu...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71436</th>\n",
       "      <td>5acf762a77cf76001a684e67</td>\n",
       "      <td>How are the leads of an axially configured ca...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71437</th>\n",
       "      <td>5acf762a77cf76001a684e68</td>\n",
       "      <td>How could radial leads be less correctly desc...</td>\n",
       "      <td>[Capacitors, may, have, their, connecting, lea...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qas_id  ... is_impossible\n",
       "71428  572719a45951b619008f85f7  ...         False\n",
       "71429  572719a45951b619008f85f8  ...         False\n",
       "71430  572719a45951b619008f85f9  ...         False\n",
       "71431  572719a45951b619008f85fa  ...         False\n",
       "71432  572719a45951b619008f85fb  ...         False\n",
       "71433  5acf762a77cf76001a684e64  ...          True\n",
       "71434  5acf762a77cf76001a684e65  ...          True\n",
       "71435  5acf762a77cf76001a684e66  ...          True\n",
       "71436  5acf762a77cf76001a684e67  ...          True\n",
       "71437  5acf762a77cf76001a684e68  ...          True\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data.sample(frac=1).head(1)\n",
    "context = sample.doc_tokens.values\n",
    "train_data[train_data.doc_tokens.values==context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86ObEyQtkqjs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def print_squad_sample(train_data, line_length=14, separator_length=120):\n",
    "  sample = train_data.sample(frac=1).head(1)\n",
    "  context = sample.doc_tokens.values\n",
    "  print('='*separator_length)\n",
    "  print('CONTEXT: ')\n",
    "  print('='*separator_length)\n",
    "  lines = [' '.join(context[0][idx:idx+line_length]) for idx in range(0, len(context[0]), line_length)]\n",
    "  for l in lines:\n",
    "      print(l)\n",
    "  print('='*separator_length)\n",
    "  questions = train_data[train_data.doc_tokens.values==context]\n",
    "  print('QUESTION:', ' '*(3*separator_length//4), 'ANSWER:')\n",
    "  for idx, row in questions.iterrows():\n",
    "    question = row.question_text\n",
    "    answer = row.orig_answer_text\n",
    "    print(question, ' '*(3*separator_length//4-len(question)+9), (answer if answer else 'No awnser found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU4S6x0YnnPT",
    "outputId": "06c271bb-a9ab-47e7-fc40-4730e3cee02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "CONTEXT: \n",
      "========================================================================================================================\n",
      "There do exist orbits within these empty regions where objects can survive for the\n",
      "age of the Solar System. These resonances occur when Neptune's orbital period is a\n",
      "precise fraction of that of the object, such as 1:2, or 3:4. If, say,\n",
      "an object orbits the Sun once for every two Neptune orbits, it will only\n",
      "complete half an orbit by the time Neptune returns to its original position. The\n",
      "most heavily populated resonance in the Kuiper belt, with over 200 known objects, is\n",
      "the 2:3 resonance. Objects in this resonance complete 2 orbits for every 3 of\n",
      "Neptune, and are known as plutinos because the largest of the known Kuiper belt\n",
      "objects, Pluto, is among them. Although Pluto crosses Neptune's orbit regularly, the 2:3 resonance\n",
      "ensures they can never collide. The 3:4, 3:5, 4:7 and 2:5 resonances are less\n",
      "populated.\n",
      "========================================================================================================================\n",
      "QUESTION:                                                                                            ANSWER:\n",
      "What is the fraction of the most heavily populated resonance in the Kuiper belt?                     2:3 resonance\n",
      "How many known objects is in the most populated resonance of the Kuiper belt?                        200\n",
      "What is the best known, and largest, object in the Kuiper belt?                                      Pluto\n",
      "What is the resonance of Pluto in the Kuiper belt?                                                   2:3\n",
      "Which resonances are less populated in the Kuiper belt?                                              3:4, 3:5, 4:7 and 2:5\n",
      "What is the fraction of the most heavily populated resonance in the Jupiter belt?                    No awnser found\n",
      "How many unknown objects is in the most populated resonance of the Kuiper belt?                      No awnser found\n",
      " What is the least known object in the Kuiper belt?                                                  No awnser found\n",
      " Which resonances are more populated in the Kuiper belt?                                             No awnser found\n",
      " What is the resonance of Jupiter in the Kuiper belt?                                                No awnser found\n"
     ]
    }
   ],
   "source": [
    "print_squad_sample(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "H3yDIGj8t1_M",
    "outputId": "333eb294-5964-4bc6-86e0-8de8d376f7a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qas_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>doc_tokens</th>\n",
       "      <th>orig_answer_text</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>paragraph_len</th>\n",
       "      <th>question_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42912</th>\n",
       "      <td>5ad0cde4645df0001a2d0407</td>\n",
       "      <td>What is the acronym for the Organization for t...</td>\n",
       "      <td>[Eritrea, is, a, member, of, the, United, Nati...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79721</th>\n",
       "      <td>5727c090ff5b5019007d9468</td>\n",
       "      <td>What is a pipe named at?</td>\n",
       "      <td>[USB, device, communication, is, based, on, pi...</td>\n",
       "      <td>an endpoint</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28213</th>\n",
       "      <td>56fdc67a19033b140034cd6d</td>\n",
       "      <td>Where was the Roman abacus first used?</td>\n",
       "      <td>[The, abacus, was, initially, used, for, arith...</td>\n",
       "      <td>Babylonia</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95793</th>\n",
       "      <td>5acd189307355d001abf348b</td>\n",
       "      <td>Who discovered the link between mechanical wor...</td>\n",
       "      <td>[In, 1807,, Thomas, Young, was, possibly, the,...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90979</th>\n",
       "      <td>57299ef46aef05140015503d</td>\n",
       "      <td>Lice and bed bugs are considered what kind of ...</td>\n",
       "      <td>[Many, insects, are, considered, pests, by, hu...</td>\n",
       "      <td>parasitic</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qas_id  ... question_len\n",
       "42912  5ad0cde4645df0001a2d0407  ...           81\n",
       "79721  5727c090ff5b5019007d9468  ...           24\n",
       "28213  56fdc67a19033b140034cd6d  ...           38\n",
       "95793  5acd189307355d001abf348b  ...           74\n",
       "90979  57299ef46aef05140015503d  ...           53\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['paragraph_len'] = None\n",
    "train_data['question_len'] = None\n",
    "for i in range(len(train_data.index)):\n",
    "  train_data['paragraph_len'][i] = len(train_data['doc_tokens'][i])   ## get the length of 'doc_tokens'  \n",
    "  train_data['question_len'][i] = len(train_data['question_text'][i])  ## get the length of 'question_text' here  \n",
    "   #train_data.loc[i,'paragraph_len'] = pd.Series(len(train_data['doc_tokens'][i]), index=train_data.index)\n",
    "train_data.sample(frac=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2VduHO4WoXwp",
    "outputId": "b7604809-4f8b-4e52-843b-643b4f091c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of context's less than max_seq_length = 98.19289589392184%\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "print(\"Percentage of context's less than max_seq_length = %s%%\" % (len([l for l in train_data['paragraph_len'] if l <= max_seq_length])/len(train_data) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6t5DqC3KlmV"
   },
   "outputs": [],
   "source": [
    "model = 'distilbert-base-uncased' ## choose model https://huggingface.co/models like you can choose basic models such as 'bert-base-uncased' or 'bert-large-uncased' or others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zywEw_BZtx5l",
    "outputId": "57ec4337-8e51-47f3-f0b7-ea781f7f1481"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 5743339.55B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dj9SoVnuSh2"
   },
   "outputs": [],
   "source": [
    "doc_stride = 128\n",
    "max_seq_length = 256\n",
    "max_query_length = 64\n",
    "# batch size of 64 if RAM available.\n",
    "batch_size =  10 # choose 4 - 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DS2oM0q3pdni"
   },
   "outputs": [],
   "source": [
    "cached_features_file = 'cache_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad8wClHXD20O",
    "outputId": "479283b4-9ff9-4290-852c-22de4586772b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDZicTC_5Gbs"
   },
   "outputs": [],
   "source": [
    "example = enumerate(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6QPrkmO5OWZ",
    "outputId": "240d839f-ef2d-40ba-8fef-b9c5a8872d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enumerate"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMqo_TFyElVE"
   },
   "outputs": [],
   "source": [
    "examples = examples[:1000]## choose first 1000 or 10000 more depending on percentage of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxXiC4G2uUwa"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(cached_features_file):\n",
    "  features = convert_examples_to_features(examples=examples,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        max_seq_length=max_seq_length,\n",
    "                                        doc_stride=doc_stride,\n",
    "                                        max_query_length=max_query_length,\n",
    "                                        is_training=True)\n",
    "  # torch.save(features, cached_features_file)\n",
    "else:\n",
    "  features = torch.load(cached_features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqKRwvvjuW1I"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8wpGNktunPQ"
   },
   "outputs": [],
   "source": [
    "# Convert to Tensors and build dataset\n",
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long) ## similarly convert tensor for input mask\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)## similarly convert tensor for segment ids\n",
    "all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)## similarly convert tensor for cls index\n",
    "all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.long)## similarly convert tensor for p mask\n",
    "\n",
    "all_start_positions = torch.tensor([f.start_position for f in features], dtype=torch.long) ## similarly convert tensor for start position\n",
    "all_end_positions = torch.tensor([f.end_position for f in features], dtype=torch.long)  ## similarly convert tensor for end position\n",
    "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                        all_start_positions, all_end_positions,\n",
    "                        all_cls_index, all_p_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siznTVwRuvkC"
   },
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(dataset)\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfJGpCMcu01s"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "checkpoints = sorted(glob.glob('checkpoint*-[0-9]*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE-mmGhwIJWe"
   },
   "outputs": [],
   "source": [
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d06HFmPmu3Yq",
    "outputId": "dfe111be-be7b-438b-c4c3-f10ea36cfc78"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:00<00:00, 174647.42B/s]\n",
      "100%|██████████| 267967963/267967963 [00:03<00:00, 82350478.82B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(checkpoints) > 0:\n",
    "  global_step = checkpoints[-1].split('-')[-1]\n",
    "  ckpt_name = 'checkpoint-{}'.format(global_step)\n",
    "  print(\"Loading model from checkpoint %s\" % ckpt_name)\n",
    "  model = BertForQuestionAnswering.from_pretrained(ckpt_name)\n",
    "  train_loss_set_ckpt = torch.load(ckpt_name + '/training_loss.pt')\n",
    "  train_loss_set = to_list(train_loss_set_ckpt)\n",
    "  tr_loss = train_loss_set[-1]\n",
    "else:\n",
    "  global_step = 0\n",
    "  train_loss_set = []\n",
    "  tr_loss = 0.0\n",
    "  model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased')  ## choose model https://huggingface.co/models like you can choose basic models such as 'bert-base-uncased' or 'bert-large-uncased' or others\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_t19YTyEu5V4",
    "outputId": "70d8f220-60f7-417a-ec89-c70894b0ccbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('qa_outputs.weight', Parameter containing:\n",
      "tensor([[-0.0116, -0.0066,  0.0267,  ...,  0.0147, -0.0089, -0.0401],\n",
      "        [-0.0216, -0.0395, -0.0038,  ..., -0.0217, -0.0134, -0.0201]],\n",
      "       device='cuda:0', requires_grad=True))\n",
      "('qa_outputs.bias', Parameter containing:\n",
      "tensor([0., 0.], device='cuda:0', requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "print(param_optimizer[-2])\n",
    "print(param_optimizer[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9alnEO5Uu7jm"
   },
   "outputs": [],
   "source": [
    "learning_rate = 10000## choose between 1e3 to 1e5\n",
    "adam_epsilon= 500000000## choose between 1e8 1e9\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGwiPd3ju9A1",
    "outputId": "c4c42730-b1e6-4ec5-f30b-f0d119c47f20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   0%|          | 0/120 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1202\n",
      "  Num Epochs = 2\n",
      "  Batch size = 10\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   2%|▏         | 2/120 [00:00<00:12,  9.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   2%|▎         | 3/120 [00:00<00:14,  7.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   3%|▎         | 4/120 [00:00<00:16,  7.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   4%|▍         | 5/120 [00:00<00:17,  6.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   5%|▌         | 6/120 [00:02<00:56,  2.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   6%|▌         | 7/120 [00:02<00:45,  2.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   7%|▋         | 8/120 [00:02<00:37,  3.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   8%|▊         | 9/120 [00:02<00:31,  3.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   8%|▊         | 10/120 [00:02<00:27,  3.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   9%|▉         | 11/120 [00:04<01:00,  1.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  10%|█         | 12/120 [00:04<00:47,  2.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  11%|█         | 13/120 [00:04<00:38,  2.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  12%|█▏        | 14/120 [00:04<00:32,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  12%|█▎        | 15/120 [00:04<00:27,  3.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  13%|█▎        | 16/120 [00:05<00:57,  1.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  14%|█▍        | 17/120 [00:06<00:45,  2.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  15%|█▌        | 18/120 [00:06<00:36,  2.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  16%|█▌        | 19/120 [00:06<00:30,  3.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  17%|█▋        | 20/120 [00:06<00:26,  3.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  18%|█▊        | 21/120 [00:07<00:55,  1.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  18%|█▊        | 22/120 [00:08<00:43,  2.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  19%|█▉        | 23/120 [00:08<00:35,  2.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  20%|██        | 24/120 [00:08<00:29,  3.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  21%|██        | 25/120 [00:08<00:25,  3.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  22%|██▏       | 26/120 [00:10<01:01,  1.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  22%|██▎       | 27/120 [00:10<00:47,  1.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  23%|██▎       | 28/120 [00:10<00:38,  2.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  24%|██▍       | 29/120 [00:10<00:31,  2.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  25%|██▌       | 30/120 [00:10<00:26,  3.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  26%|██▌       | 31/120 [00:14<02:05,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  27%|██▋       | 32/120 [00:15<01:32,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  28%|██▊       | 33/120 [00:15<01:08,  1.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  28%|██▊       | 34/120 [00:15<00:52,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  29%|██▉       | 35/120 [00:15<00:41,  2.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  30%|███       | 36/120 [00:21<02:49,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  31%|███       | 37/120 [00:21<02:02,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  32%|███▏      | 38/120 [00:21<01:29,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  32%|███▎      | 39/120 [00:21<01:06,  1.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  33%|███▎      | 40/120 [00:22<00:50,  1.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  34%|███▍      | 41/120 [00:24<01:23,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  35%|███▌      | 42/120 [00:24<01:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  36%|███▌      | 43/120 [00:24<00:47,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  37%|███▋      | 44/120 [00:24<00:36,  2.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  38%|███▊      | 45/120 [00:24<00:29,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  38%|███▊      | 46/120 [00:34<03:50,  3.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  39%|███▉      | 47/120 [00:34<02:43,  2.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  40%|████      | 48/120 [00:34<01:56,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  41%|████      | 49/120 [00:34<01:24,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  42%|████▏     | 50/120 [00:35<01:02,  1.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  42%|████▎     | 51/120 [00:40<02:43,  2.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  43%|████▎     | 52/120 [00:41<01:56,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  44%|████▍     | 53/120 [00:41<01:24,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  45%|████▌     | 54/120 [00:41<01:02,  1.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  46%|████▌     | 55/120 [00:41<00:46,  1.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  47%|████▋     | 56/120 [00:43<01:07,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  48%|████▊     | 57/120 [00:43<00:49,  1.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  48%|████▊     | 58/120 [00:43<00:37,  1.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  49%|████▉     | 59/120 [00:44<00:29,  2.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  50%|█████     | 60/120 [00:44<00:23,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  51%|█████     | 61/120 [00:49<01:44,  1.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  52%|█████▏    | 62/120 [00:49<01:14,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  52%|█████▎    | 63/120 [00:49<00:54,  1.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  53%|█████▎    | 64/120 [00:49<00:40,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  54%|█████▍    | 65/120 [00:49<00:30,  1.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  55%|█████▌    | 66/120 [00:56<02:08,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  56%|█████▌    | 67/120 [00:56<01:30,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  57%|█████▋    | 68/120 [00:56<01:05,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  57%|█████▊    | 69/120 [00:56<00:47,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  58%|█████▊    | 70/120 [00:57<00:34,  1.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  59%|█████▉    | 71/120 [01:05<02:24,  2.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  60%|██████    | 72/120 [01:05<01:41,  2.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  61%|██████    | 73/120 [01:05<01:12,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  62%|██████▏   | 74/120 [01:05<00:51,  1.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  62%|██████▎   | 75/120 [01:06<00:37,  1.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  63%|██████▎   | 76/120 [01:14<02:22,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  64%|██████▍   | 77/120 [01:15<01:40,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  65%|██████▌   | 78/120 [01:15<01:11,  1.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  66%|██████▌   | 79/120 [01:15<00:50,  1.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  67%|██████▋   | 80/120 [01:15<00:37,  1.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  68%|██████▊   | 81/120 [01:17<00:49,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  68%|██████▊   | 82/120 [01:17<00:35,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  69%|██████▉   | 83/120 [01:18<00:26,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  70%|███████   | 84/120 [01:18<00:20,  1.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  71%|███████   | 85/120 [01:18<00:15,  2.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  72%|███████▏  | 86/120 [01:27<01:44,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  72%|███████▎  | 87/120 [01:27<01:12,  2.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  73%|███████▎  | 88/120 [01:28<00:51,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  74%|███████▍  | 89/120 [01:28<00:36,  1.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  75%|███████▌  | 90/120 [01:28<00:26,  1.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  76%|███████▌  | 91/120 [01:30<00:35,  1.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  77%|███████▋  | 92/120 [01:30<00:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  78%|███████▊  | 93/120 [01:30<00:18,  1.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  78%|███████▊  | 94/120 [01:31<00:14,  1.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  79%|███████▉  | 95/120 [01:31<00:10,  2.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  80%|████████  | 96/120 [01:41<01:21,  3.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration:  81%|████████  | 97/120 [01:41<00:55,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  82%|████████▏ | 98/120 [01:41<00:38,  1.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  82%|████████▎ | 99/120 [01:42<00:27,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  83%|████████▎ | 100/120 [01:42<00:19,  1.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  84%|████████▍ | 101/120 [01:44<00:25,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  85%|████████▌ | 102/120 [01:44<00:18,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  86%|████████▌ | 103/120 [01:44<00:13,  1.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  87%|████████▋ | 104/120 [01:45<00:09,  1.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  88%|████████▊ | 105/120 [01:45<00:07,  2.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  88%|████████▊ | 106/120 [01:55<00:45,  3.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  89%|████████▉ | 107/120 [01:55<00:30,  2.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  90%|█████████ | 108/120 [01:55<00:20,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  91%|█████████ | 109/120 [01:55<00:13,  1.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  92%|█████████▏| 110/120 [01:55<00:09,  1.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  92%|█████████▎| 111/120 [02:02<00:22,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  93%|█████████▎| 112/120 [02:02<00:14,  1.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  94%|█████████▍| 113/120 [02:02<00:09,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  95%|█████████▌| 114/120 [02:02<00:05,  1.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  96%|█████████▌| 115/120 [02:02<00:03,  1.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  97%|█████████▋| 116/120 [02:08<00:08,  2.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  98%|█████████▊| 117/120 [02:08<00:04,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkpoint-115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  98%|█████████▊| 118/120 [02:08<00:02,  1.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:  99%|█████████▉| 119/120 [02:08<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 100%|██████████| 120/120 [02:08<00:00,  1.07s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [02:08<02:08, 128.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 100%|██████████| 120/120 [00:00<00:00, 2213.78it/s]\n",
      "Epoch: 100%|██████████| 2/2 [02:08<00:00, 64.47s/it] \n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 2 ## choose 1 to 3 \n",
    "\n",
    "print(\"***** Running training *****\")\n",
    "print(\"  Num examples = %d\" % len(dataset))\n",
    "print(\"  Num Epochs = %d\" % num_train_epochs)\n",
    "print(\"  Batch size = %d\" % batch_size)\n",
    "print(\"  Total optimization steps = %d\" % (len(train_dataloader) // num_train_epochs))\n",
    "\n",
    "model.zero_grad()\n",
    "train_iterator = trange(num_train_epochs, desc=\"Epoch\")\n",
    "set_seed()\n",
    "\n",
    "for _ in train_iterator:\n",
    "    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "      if step < global_step + 1:\n",
    "        continue\n",
    "\n",
    "      model.train()\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "#'token_type_ids':  batch[2], \n",
    "      inputs = {'input_ids':       batch[0],\n",
    "                'attention_mask':  batch[1],  \n",
    "                'start_positions': batch[3], \n",
    "                'end_positions':   batch[4]}\n",
    "\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "      loss = outputs[0]\n",
    "      train_loss_set.append(loss)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "      tr_loss += loss.item()\n",
    "      optimizer.step()\n",
    "      model.zero_grad()\n",
    "      global_step += 1\n",
    "    \n",
    "      if global_step % 5  == 0: ## choose a number where you want to save\n",
    "        print(\"Train loss: {}\".format(tr_loss/global_step))\n",
    "        output_dir = 'checkpoint-{}'.format(global_step)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "        model_to_save.save_pretrained(output_dir)\n",
    "        torch.save(torch.tensor(train_loss_set), os.path.join(output_dir, 'training_loss.pt'))\n",
    "        print(\"Saving model checkpoint to %s\" % output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUfeq9kO1oYM"
   },
   "outputs": [],
   "source": [
    "output_dir = 'checkpoint-final'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpoznGAgYcWE"
   },
   "outputs": [],
   "source": [
    "train_loss_set_ckpt = torch.load('checkpoint-115/training_loss.pt')\n",
    "train_loss_set = to_list(train_loss_set_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "-z2GxIeN1vqa",
    "outputId": "07868841-0ab7-4df8-851e-b2391d152a52"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(train_loss_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TglKsny312Oh"
   },
   "outputs": [],
   "source": [
    "input_file = 'dev-v2.0.json'\n",
    "val_examples = read_squad_examples(input_file=input_file,\n",
    "                                is_training=False,\n",
    "                                version_2_with_negative=True)\n",
    "doc_stride = 128\n",
    "max_seq_length = 256\n",
    "max_query_length = 64\n",
    "cached_features_file = 'cache_validation'\n",
    "\n",
    "# Cache features for faster loading\n",
    "if not os.path.exists(cached_features_file):\n",
    "  features = convert_examples_to_features(examples=val_examples,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        max_seq_length=max_seq_length,\n",
    "                                        doc_stride=doc_stride,\n",
    "                                        max_query_length=max_query_length,\n",
    "                                        is_training=False)\n",
    "  torch.save(features, cached_features_file)\n",
    "else:\n",
    "  features = torch.load(cached_features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLmoahbz1_Hx"
   },
   "outputs": [],
   "source": [
    "# Convert to Tensors and build dataset\n",
    "# Convert to Tensors and build dataset\n",
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long) ## similarly convert tensor for input mask\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)## similarly convert tensor for segment ids\n",
    "all_cls_index = torch.tensor([f.cls_index for f in features], dtype=torch.long)## similarly convert tensor for cls index\n",
    "all_p_mask = torch.tensor([f.p_mask for f in features], dtype=torch.long)## similarly convert tensor for p mask\n",
    "\n",
    "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                        all_example_index, all_cls_index, all_p_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMMV4KIh2OKt"
   },
   "outputs": [],
   "source": [
    "validation_sampler = SequentialSampler(dataset)\n",
    "validation_dataloader = DataLoader(dataset, sampler=validation_sampler, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3_CAQUf2asD"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, tokenizer):\n",
    "  print(\"***** Running evaluation *****\")\n",
    "  print(\"  Num examples = %d\" % len(dataset))\n",
    "  print(\"  Batch size = %d\" % batch_size)\n",
    "  all_results = []\n",
    "  predict_file = 'dev-v2.0.json'\n",
    "  for batch in tqdm(validation_dataloader, desc=\"Evaluating\", miniters=100, mininterval=5.0):\n",
    "    model.eval()\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "      inputs = {'input_ids':      batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                #'token_type_ids': batch[2]\n",
    "                }\n",
    "      example_indices = batch[3]\n",
    "      outputs = model(**inputs)\n",
    "\n",
    "    for i, example_index in enumerate(example_indices):\n",
    "      eval_feature = features[example_index.item()]\n",
    "      unique_id = int(eval_feature.unique_id)\n",
    "\n",
    "      result = RawResult(unique_id    = unique_id,\n",
    "                         start_logits = to_list(outputs[0][i]),\n",
    "                         end_logits   = to_list(outputs[1][i]))\n",
    "      all_results.append(result)\n",
    "\n",
    "  # Compute predictions\n",
    "  output_prediction_file = \"predictions.json\"\n",
    "  output_nbest_file = \"nbest_predictions.json\"\n",
    "  output_null_log_odds_file = \"null_odds.json\"\n",
    "  output_dir = \"predict_results\"\n",
    "\n",
    "  write_predictions(val_examples, features, all_results, 10,\n",
    "                  30, True, output_prediction_file,\n",
    "                  output_nbest_file, output_null_log_odds_file, False,\n",
    "                  True, 0.0)\n",
    "\n",
    "  # Evaluate with the official SQuAD script\n",
    "  evaluate_options = EVAL_OPTS(data_file=predict_file,\n",
    "                               pred_file=output_prediction_file,\n",
    "                               na_prob_file=output_null_log_odds_file,\n",
    "                               out_image_dir=None)\n",
    "  results = evaluate_on_squad(evaluate_options)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROJlB2Np2iTo",
    "outputId": "f4e92819-72e4-4ae6-d7a4-15e752f63134"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:   0%|          | 0/1360 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "  Num examples = 13600\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:   7%|▋         | 100/1360 [00:05<01:05, 19.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  15%|█▍        | 200/1360 [00:10<01:00, 19.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  22%|██▏       | 300/1360 [00:15<00:55, 19.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  29%|██▉       | 400/1360 [00:20<00:50, 19.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  37%|███▋      | 500/1360 [00:26<00:44, 19.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  44%|████▍     | 600/1360 [00:31<00:39, 19.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  51%|█████▏    | 700/1360 [00:36<00:34, 19.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  59%|█████▉    | 800/1360 [00:41<00:29, 19.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  66%|██████▌   | 900/1360 [00:46<00:23, 19.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  74%|███████▎  | 1000/1360 [00:52<00:18, 19.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  81%|████████  | 1100/1360 [00:57<00:13, 19.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  88%|████████▊ | 1200/1360 [01:02<00:08, 19.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Evaluating: 100%|██████████| 1360/1360 [01:10<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact\": 47.39324517813527,\n",
      "  \"f1\": 47.450638379003436,\n",
      "  \"total\": 11873,\n",
      "  \"HasAns_exact\": 0.0,\n",
      "  \"HasAns_f1\": 0.11495099087512396,\n",
      "  \"HasAns_total\": 5928,\n",
      "  \"NoAns_exact\": 94.65096719932717,\n",
      "  \"NoAns_f1\": 94.65096719932717,\n",
      "  \"NoAns_total\": 5945,\n",
      "  \"best_exact\": 50.07159100480081,\n",
      "  \"best_exact_thresh\": 0.0,\n",
      "  \"best_f1\": 50.07159100480081,\n",
      "  \"best_f1_thresh\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_Hg-0Xw5WRr",
    "outputId": "73c0fa62-1e9e-4498-ec93-5ea2b3c6a5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'exact': 47.39324517813527}, {'f1': 47.450638379003436}, {'total': 11873}, {'HasAns_exact': 0.0}, {'HasAns_f1': 0.11495099087512396}, {'HasAns_total': 5928}, {'NoAns_exact': 94.65096719932717}, {'NoAns_f1': 94.65096719932717}, {'NoAns_total': 5945}, {'best_exact': 50.07159100480081}, {'best_exact_thresh': 0.0}, {'best_f1': 50.07159100480081}, {'best_f1_thresh': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "results_json = []\n",
    "for k in enumerate(results.keys()):\n",
    "  result_dict = {k[1] : results[k[1]]}\n",
    "  results_json.append(result_dict)\n",
    "print(results_json)\n",
    "with open('results.json', 'w') as f:\n",
    "  json.dump(results_json, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
